{
    "@graph": [
        {
            "@id": "gnd:1092325816",
            "sameAs": "Ruckdeschel, Peter"
        },
        {
            "@id": "gnd:1203400942",
            "sameAs": "Werner, Tino"
        },
        {
            "@id": "gnd:4121498-5",
            "sameAs": "Prädiktor"
        },
        {
            "@id": "gnd:4126634-1",
            "sameAs": "Asymptotik"
        },
        {
            "@id": "gnd:4307945-3",
            "sameAs": "Ranking"
        },
        {
            "@id": "gnd:4323954-7",
            "sameAs": "Gradient"
        },
        {
            "@id": "gnd:4839853-6",
            "sameAs": "Boosting"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1691628751",
            "@type": "bibo:Thesis",
            "P1053": "1 Online-Ressource (xxviii, 390 Seiten, 2,7 MB)",
            "http://purl.org/dc/elements/1.1/contributor": "Schmid, Matthias",
            "identifier": [
                "(firstid)DNB:120419968X",
                "(ppn)1691628751"
            ],
            "http://purl.org/dc/elements/1.1/subject": [
                "(classificationName=ddc)519.53",
                "(classificationName=ddc-dbn)510",
                "(classificationName=linseach:mapping)mat"
            ],
            "title": "Gradient-Free Gradient Boosting",
            "abstract": [
                "Motiviert durch Anwendungen in der Betrugsdetektion beschäftigt sich die Dissertation mit der Modellwahl in prädiktiven Modellen, in denen das korrekte Ranking von Beobachtungen vorhergesagt werden soll. Hierzu beweist die Arbeit zunächst die asymptotische Linearität einer ganzen Familie regularisierter M-Schätzer, die u.A. das Lasso abdeckt. Mit dem in der Dissertation entwickelten Verfahren ,,SingBoost&apos;&apos; gelingt es, trotz unstetiger Verlustfunktion auch im Rankingproblem ein Gradienten-Boosting in Erweiterung des L2-Boostings bereitzustellen. Wir beweisen: Dieser Algorithmus besitzt entsprechende Konsistenz-Eigenschaften wie das L2-Boosting. Für eine stabile Modellwahl wird eine verlustbasierte Stabilitätsselektion entwickelt. Auf simulierten Daten verbessert SingBoost verbunden mit dieser Stabilitätsselektion die Performance für das harte stetige Rankingproblem strikt. Die hierzu entwickelte Stabilitätsselektion ist dabei universell, für beliebige Verlustfunktionen, einsetzbar.",
                "Motivated by applications in fraud detection, this dissertation is concerned about model selection in predictive models where the correct ranking of observations has to be predicted. For this, the thesis starts by proving the asymptotic linearity of a whole family of regularized M-estimators which covers for example the Lasso. With the algorithm &apos;&apos;SingBoost&apos;&apos; developed in this dissertation, we succeed in providing a Gradient Boosting algorithm as an extension of L2-Boosting, even though the loss function is non-continuous. We prove: This algorithm has analogous consistency properties as L2-Boosting. As to stable model selection, we develop a loss-based Stability Selection. In combination with this Stability Selection, SingBoost strictly improves the performance for the hard ranking problem on simulated data. The loss-based Stability Selection that we provide is universally applicable, i.e., for arbitrary loss functions."
            ],
            "alternative": "Gradientenfreies Gradienten-Boosting",
            "contributor": [
                "Technische Informationsbibliothek (TIB)",
                {
                    "@id": "gnd:1092325816"
                }
            ],
            "creator": "gnd:1203400942",
            "isPartOf": "(collectioncode)GBV-ODiss",
            "issued": "2020",
            "language": "http://id.loc.gov/vocabulary/iso639-1/de",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "subject": [
                "gnd:4307945-3",
                "gnd:4839853-6",
                "gnd:4126634-1",
                "gnd:4121498-5",
                "gnd:4323954-7"
            ],
            "P60163": "Oldenburg"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "subject": {
            "@id": "http://purl.org/dc/terms/subject",
            "@type": "@id"
        },
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "title": "http://purl.org/dc/elements/1.1/title",
        "contributor": "http://purl.org/dc/terms/contributor",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "abstract": "http://purl.org/dc/terms/abstract",
        "alternative": "http://purl.org/dc/terms/alternative",
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "issued": "http://purl.org/dc/terms/issued",
        "license": "http://purl.org/dc/terms/license",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}