{
    "@graph": [
        {
            "@id": "gnd:1211371557",
            "sameAs": "Hesse, Nikolas"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1703786424",
            "@type": "bibo:Thesis",
            "P1053": "1 Online-Ressource (194 Seiten)",
            "description": "Illustrationen, Diagramme",
            "identifier": [
                "(contract)FRUB-opus-165847",
                "(ppn)1703786424",
                "(doi)10.6094/UNIFR/165847",
                "(firstid)KXP:1703786424"
            ],
            "title": "Unobtrusive medical infant motion analysis from RGB-D data",
            "abstract": "Abstract: Cerebral palsy (CP) is the most common motor disorder in children, and is caused by injuries of the brain shortly before, during, or after birth. With traditional methods, a reliable diagnosis of CP can generally not be made until after the first year of life or even later. Based on the discovery that the condition of the nervous system of young infants is reflected in the quality of their spontaneous movements, the general movement assessment (GMA) was developed. GMA lets trained experts detect CP in infants as young as four months. However, regular practice and re-calibration are required, and GMA suffers from human variability. CP manifests itself in a variety of symptoms, which complicates finding the right parameters for predicting the risk of CP.<br>A cheap, automated system would allow the widespread screening of infants in order to concentrate early intervention efforts on affected children. We divide the system into the motion capture stage and the motion analysis stage. Although the extraction of motion, respectively body pose, from images and videos is a very active area of computer vision research, most of the proposed approaches focus on adults and can not be directly transferred to infants.<br>In this thesis, we present multiple contributions towards an unobtrusive system for medical motion analysis of infants. First, we propose an approach for estimating 3D pose from depth images, speeding up the training procedure by nearly two orders of magnitude compared to previous approaches. Second, we develop a model-based approach for markerless full-body tracking. We learn the Skinned Multi-Infant Linear model (SMIL) from low-quality RGB-D data and accurately register it to sequences of moving infants, capturing shape and pose while handling self-occlusions and fast movements. We show that our method captures enough motion detail for GMA. Third, we develop an approach towards predicting the GMA class from motion sequences, which is based on features of motion complexity and variation to capture characteristics of general movements. <br>Our methods enable accurate tracking of infant shape and pose, and enable  applications like monitoring of therapy/disease progression, tracking growth or motor development, and detection of malnutrition. By publicly releasing the learned model and a synthetic, but realistic data set of moving infants, we hope to foster research focused on infants",
            "contributor": [
                "Technische Informationsbibliothek (TIB)",
                {
                    "@id": "gnd:1136138307"
                }
            ],
            "creator": "gnd:1211371557",
            "isPartOf": "(collectioncode)GBV-ODiss",
            "issued": "2019",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "isLike": "doi:10.6094/UNIFR/165847",
            "P60163": "Freiburg im Breisgau"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "title": "http://purl.org/dc/elements/1.1/title",
        "contributor": "http://purl.org/dc/terms/contributor",
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "description": "http://purl.org/dc/elements/1.1/description",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "issued": "http://purl.org/dc/terms/issued",
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "license": "http://purl.org/dc/terms/license",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "abstract": "http://purl.org/dc/terms/abstract",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}