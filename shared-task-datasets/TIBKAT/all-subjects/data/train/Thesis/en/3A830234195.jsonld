{
    "@graph": [
        {
            "@id": "gnd:1074303539",
            "sameAs": "Gressmann, Markus"
        },
        {
            "@id": "gnd:4056783-7",
            "sameAs": "Stadtverkehr"
        },
        {
            "@id": "gnd:4140907-3",
            "sameAs": "Fu\u00dfg\u00e4nger"
        },
        {
            "@id": "gnd:4264283-8",
            "sameAs": "Bilderkennung"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A830234195",
            "@type": "bibo:Thesis",
            "P1053": "Online-Ressource",
            "identifier": [
                "(firstid)BSZ:434713562",
                "(ppn)830234195"
            ],
            "subject": [
                "(classificationName=linseach:mapping)inf",
                "(classificationName=linseach:mapping)ver",
                "Klassifikation",
                "Pedestrians",
                "(classificationName=ddc-dbn)620",
                "Neural networks (Computer science)",
                "Erkennung",
                "(classificationName=ddc)004",
                "(classificationName=bk, id=10642064X)55.84 - Stra\u00dfenverkehr",
                "(classificationName=bk, id=10641030X)54.74 - Maschinelles Sehen",
                "Fu\u00dfg\u00e4nger",
                "Machine learning",
                "Classification"
            ],
            "title": "Surround View pedestrian detection",
            "abstract": "In this thesis, novel methods that enable and support Surround View pedestrian detection are developed. As a part of the so called Surround View System, the introduced detection and localization approaches can be used to prevent and mitigate accidents involving pedestrians. We begin by giving a complete description of the processing chain required to find pedestrians in the input images obtained from four wide-angle cameras. Then, a novel heterogeneous cascaded classifier approach is introduced, which combines the computational efficiency of early simple stages with the classification performance of powerful final stages. In order to further increase the performance of our heterogeneous cascade, a feature-based inter-stage information transfer algorithm is introduced. To deal with occlusions caused by the mounting positions of the cameras, a classification scheme is introduced to also handle only partially visible pedestrians. To complement the intensity-image based classification approach, we propose to use a multi-stage rejection chain employing dense optical flow. It is shown that by analyzing dense flow images and egomotion information of the current scene, the likelihood that an image window contains a pedestrian can be inferred. The approach incorporates the uncertainties of all inputs which is important when dealing with the noisy data received from the flow- and egomotion-estimation. Due to the way that detected pedestrians are displayed in the Surround View System, the detection location in the image must be very precise. It is shown how localization can be treated as a subsequent step to pedestrian detection that aims at finding the exact position of pedestrians in an input image. Then, two different novel approaches for pedestrian localization using neural networks with local receptive fields are introduced and evaluated.",
            "contributor": "Technische Informationsbibliothek (TIB)",
            "creator": "gnd:1074303539",
            "isPartOf": "(collectioncode)GBV-ODiss",
            "issued": "2015",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "dcterms:subject": [
                {
                    "@id": "gnd:4056783-7"
                },
                {
                    "@id": "gnd:4140907-3"
                },
                {
                    "@id": "gnd:4264283-8"
                }
            ]
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "license": "http://purl.org/dc/terms/license",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "issued": "http://purl.org/dc/terms/issued",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "abstract": "http://purl.org/dc/terms/abstract",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "contributor": "http://purl.org/dc/terms/contributor",
        "title": "http://purl.org/dc/elements/1.1/title",
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}