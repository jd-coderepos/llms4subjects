{
    "@graph": [
        {
            "@id": "gnd:1153501937",
            "sameAs": "Ozdemir, Sinan"
        },
        {
            "@id": "gnd:123178002",
            "sameAs": "Langenau, Frank"
        },
        {
            "@id": "gnd:1285065492",
            "sameAs": "ChatGPT"
        },
        {
            "@id": "gnd:1322631905",
            "sameAs": "Gro\u00dfes Sprachmodell"
        },
        {
            "@id": "gnd:1322633797",
            "sameAs": "Prompt Engineering"
        },
        {
            "@id": "gnd:4033447-8",
            "sameAs": "K\u00fcnstliche Intelligenz"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1880251140",
            "@type": "bibo:Book",
            "P1053": "271 Seiten",
            "description": [
                "24 cm x 16.5 cm",
                "Illustrationen, Diagramme"
            ],
            "identifier": [
                "(firstid)DNB:1317616235",
                "(isbn13)9783960092407",
                "(ppn)1880251140",
                "(ean)9783960092407"
            ],
            "publisher": "O'Reilly\u00ae",
            "subject": [
                "(classificationName=linseach:mapping)inf",
                "(classificationName=rvk)ST 306",
                "Bart",
                "Embeddings",
                "GPT-4",
                "Python",
                "OpenAI",
                "KI",
                "Prompt Engineering",
                "NLP",
                "Cohere",
                "(classificationName=ddc-dbn)004",
                "AI",
                "EleutherAI",
                "Bert",
                "Bard",
                "Machine learning",
                "Nat\u00fcrliche Sprachen und maschinelle \u00dcbersetzung",
                "Natural Language Processing",
                "COMPUTERS / Natural Language Processing",
                "COM094000",
                "LangChain",
                "Llama"
            ],
            "title": "Praxiseinstieg Large Language Models : Strategien und Best Practices f\u00fcr den Einsatz von ChatGPT und anderen LLMs",
            "abstract": "Das Buch bietet einen \u00dcberblick \u00fcber zentrale Konzepte und Techniken von LLMs wie z.B. ChatGPT und zeigt das Potenzial von Open-Source- und Closed-Source-Modellen Es erl\u00e4utert, wie Large Language Models funktionieren und wie sie f\u00fcr Aufgaben des Natural Language Processing (NLP) genutzt werden Auch f\u00fcr interessierte Nicht-Data-Scientists mit Python-Kenntnissen verst\u00e4ndlich Themen z.B.: die ChatGPT-API, Prompt-Engineering, Chatbot-Personas, Cloud-Bereitstellung; deckt auch GPT-4 ab Large Language Models (LLMs) wie ChatGPT zeigen erstaunliche F\u00e4higkeiten, aber ihre Gr\u00f6\u00dfe und Komplexit\u00e4t halten viele Praktiker_innen davon ab, sie in ihren eigenen Anwendungen einzusetzen. In dieser Einf\u00fchrung r\u00e4umt Data Scientist und KI-Unternehmer Sinan Ozdemir diese Hindernisse aus dem Weg und bietet einen Leitfaden f\u00fcr den Einsatz von LLMs zur L\u00f6sung praktischer NLP-Probleme.  Sinan Ozdemir hat alles zusammengestellt, was Sie f\u00fcr den Einstieg brauchen, auch wenn Sie noch keine Erfahrung mit LLMs haben: Schritt-f\u00fcr-Schritt-Anleitungen, Best Practices, Fallstudien aus der Praxis, \u00dcbungsaufgaben und vieles mehr. Gleichzeitig bietet er Einblicke in die Funktionsweise von LLMs, um Sie bei der Auswahl von Modellen, Datenformaten und Parametern zu unterst\u00fctzen. Auf der begleitenden Website des Autors finden Sie weitere Ressourcen, darunter Beispieldatens\u00e4tze und Code f\u00fcr die Arbeit mit Open-Source- und Closed-Source-LLMs",
            "alternative": "Quick start guide to large language models : strategies and best practices for using ChatGPT and other LLMs",
            "contributor": "gnd:123178002",
            "dcterms:contributor": "Technische Informationsbibliothek (TIB)",
            "creator": "gnd:1153501937",
            "issued": "2024",
            "language": "http://id.loc.gov/vocabulary/iso639-1/de",
            "license": "commercial licence",
            "medium": "rda:termList/RDACarrierType/1044",
            "dcterms:subject": [
                {
                    "@id": "gnd:4033447-8"
                },
                {
                    "@id": "gnd:1285065492"
                }
            ],
            "P60163": "Heidelberg"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "alternative": "http://purl.org/dc/terms/alternative",
        "title": "http://purl.org/dc/elements/1.1/title",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "contributor": {
            "@id": "http://purl.org/dc/terms/contributor",
            "@type": "@id"
        },
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "issued": "http://purl.org/dc/terms/issued",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "publisher": "http://purl.org/dc/elements/1.1/publisher",
        "license": "http://purl.org/dc/terms/license",
        "description": "http://purl.org/dc/elements/1.1/description",
        "abstract": "http://purl.org/dc/terms/abstract",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}