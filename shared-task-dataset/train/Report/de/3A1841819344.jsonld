{
    "@graph": [
        {
            "@id": "gnd:1068096934",
            "sameAs": "Universit\u00e4tsverlag Potsdam"
        },
        {
            "@id": "gnd:1155270444",
            "sameAs": "Hasso-Plattner-Institut f\u00fcr Digital Engineering"
        },
        {
            "@id": "gnd:120012162",
            "sameAs": "Hirschfeld, Robert"
        },
        {
            "@id": "gnd:4132652-0",
            "sameAs": "Softwaretest"
        },
        {
            "@id": "gnd:4133869-8",
            "sameAs": "Misserfolg"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1841819344",
            "@type": "bibo:Report",
            "P1053": "1 Online-Ressource (87 Seiten, 2786 KB)",
            "creator": [
                "D\u00fcrsch, Falco",
                "Mattis, Toni",
                "Rein, Patrick"
            ],
            "description": "Illustrationen, Diagramme",
            "identifier": [
                "(firstid)KXP:1841819344",
                "(doi)10.25932/publishup-53755",
                "(ppn)1841819344",
                "(isbn13)9783869565286"
            ],
            "publisher": "Universit\u00e4tsverlag Potsdam",
            "subject": [
                "(classificationName=linseach:mapping)inf",
                "(classificationName=bk, id=106418882)54.52 - Software engineering"
            ],
            "title": "Learning from failure : a history-based, lightweight test prioritization technique connecting software changes to test failures",
            "abstract": [
                "Regressionstests sind in der heutigen Softwareindustrie weit verbreitete Praxis um die Qualit\u00e4t eines Softwareprodukts abzusichern. Dabei leiten Entwickler von den gestellten Anforderungen Testf\u00e4lle ab und f\u00fchren diese wiederholt aus, um sicherzustellen, dass ihre \u00c4nderungen die bereits existierende Funktionalit\u00e4t nicht negativ beeintr\u00e4chtigen. Steigt die Gr\u00f6\u00dfe und Komplexit\u00e4t der Software und ihrer Testsuite, so wird die Feedbackschleife der Testausf\u00fchrungen l\u00e4nger, und mindert die Produktivit\u00e4t der Entwickler: Sie warten l\u00e4nger auf das Testergebnis, und die Fehlerbehebung gestaltet sich umso schwieriger, je l\u00e4nger die Ursache zur\u00fcckliegt. Um die Feedbackschleife zu verk\u00fcrzen, \u00e4ndern Testpriorisierungs-Algorithmen die Reihenfolge der Testf\u00e4lle, sodass Testf\u00e4lle, die mit hoher Wahrscheinlichkeit fehlschlagen, zuerst ausgef\u00fchrt werden. Der vorliegende Bericht besch\u00e4ftigt sich mit der Frage nach der Effizienz von Testpl\u00e4nen, welche aus \u00f6ffentlich einsehbaren Daten rekonstruierbar sind, und welche anwendbaren Priorisierungs-Techniken die effizienteste Testreihenfolge in Bezug auf APFD hervorbringen. Zu diesem Zweck werden 6200 Testsitzungen aus den Logdateien von Travis CI, einem oft verwendeten Dienst f\u00fcr Continuous Integration, und \u00fcber 62000 \u00c4nderungslisten rekonstruiert. Auf dieser Grundlage wird die Effizienz der derzeitigen Testpl\u00e4ne bewertet, als auch solcher, die aus der Neupriorisierung durch leichtgewichtige, verlaufsbasierte Algorithmen hervorgehen. Zudem schl\u00e4gt der vorliegende Bericht eine neue Gruppe von Ans\u00e4tzen vor, die Testfehlschl\u00e4ge und Software\u00e4nderungen mit Hilfe einer Matrix in Bezug setzt. Da die beobachteten Testreihenfolgen nur 30% APFD erzielen, liegt wesentliches Potential f\u00fcr Optimierung vor. Dabei besticht die Vorhersagekraft der unmittelbar vorangegangen Testfehlschl\u00e4ge: einfache Heuristiken, wie das Wiederholen von Tests, welche k\u00fcrzlich fehlgeschlagen sind, f\u00fchren zu Testpl\u00e4nen mit einer Effizienz von 95% APFD. Matrix-basierte Ans\u00e4tze erreichen eine Fehlererkennungsrate von bis zu 92.5% APFD. Im Gegensatz zu den bisher bekannten Ans\u00e4tzen sind die matrix-basierten Techniken auch \u00fcber den Zweck der Testpriorisierung hinaus n\u00fctzlich, und sind in der Softwarewartung anwendbar. Zus\u00e4tzlich werden die Ergebnisse der vorliegenden Studie f\u00fcr Continuous Integration Systeme im Kontext integrierter Entwicklungsumgebungen validiert, indem ein Tool f\u00fcr Continuous Testing um Testpriorisierung erweitert wird. Dies f\u00fchrt zu neuen Forschungsfragen. Die Untersuchungsergebnisse sind geeignet die Einf\u00fchrung von Continuous Testing zu bef\u00f6rdern, und untermauern, dass Werkzeuge der Testpriorisierung f\u00fcr produktive Softwareentwicklung essenziell sind.",
                "Regression testing is a widespread practice in today's software industry to ensure software product quality. Developers derive a set of test cases, and execute them frequently to ensure that their change did not adversely affect existing functionality. As the software product and its test suite grow, the time to feedback during regression test sessions increases, and impedes programmer productivity: developers wait longer for tests to complete, and delays in fault detection render fault removal increasingly difficult. Test case prioritization addresses the problem of long feedback loops by reordering test cases, such that test cases of high failure probability run first, and test case failures become actionable early in the testing process. We ask, given test execution schedules reconstructed from publicly available data, to which extent can their fault detection efficiency improved, and which technique yields the most efficient test schedules with respect to APFD? To this end, we recover regression 6200 test sessions from the build log files of Travis CI, a popular continuous integration service, and gather 62000 accompanying changelists. We evaluate the efficiency of current test schedules, and examine the prioritization results of state-of-the-art lightweight, history-based heuristics. We propose and evaluate a novel set of prioritization algorithms, which connect software changes and test failures in a matrix-like data structure. Our studies indicate that the optimization potential is substantial, because the existing test plans score only 30% APFD. The predictive power of past test failures proves to be outstanding: simple heuristics, such as repeating tests with failures in recent sessions, result in efficiency scores of 95% APFD. The best-performing matrix-based heuristic achieves a similar score of 92.5% APFD. In contrast to prior approaches, we argue that matrix-based techniques are useful beyond the scope of effective prioritization, and enable a number of use cases involving software maintenance. We validate our findings from continuous integration processes by extending a continuous testing tool within development environments with means of test prioritization, and pose further research questions. We think that our findings are suited to propel adoption of (continuous) testing practices, and that programmers' toolboxes should contain test prioritization as an existential productivity tool."
            ],
            "contributor": "Technische Informationsbibliothek (TIB)",
            "dcterms:creator": [
                {
                    "@id": "gnd:1068096934"
                },
                {
                    "@id": "gnd:1155270444"
                },
                {
                    "@id": "gnd:120012162"
                }
            ],
            "issued": "2022",
            "language": "http://id.loc.gov/vocabulary/iso639-1/de",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "dcterms:subject": [
                {
                    "@id": "gnd:4133869-8"
                },
                {
                    "@id": "gnd:4132652-0"
                }
            ],
            "volume": "Nr. 145",
            "isLike": "doi:10.25932/publishup-53755",
            "P30128": "Technische Berichte des Hasso-Plattner-Instituts f\u00fcr Digital Engineering an der Universit\u00e4t Potsdam",
            "P60163": "Potsdam"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "creator": "http://purl.org/dc/elements/1.1/creator",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "issued": "http://purl.org/dc/terms/issued",
        "description": "http://purl.org/dc/elements/1.1/description",
        "abstract": "http://purl.org/dc/terms/abstract",
        "contributor": "http://purl.org/dc/terms/contributor",
        "title": "http://purl.org/dc/elements/1.1/title",
        "P30128": "http://www.rdaregistry.info/Elements/m/#P30128",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "publisher": "http://purl.org/dc/elements/1.1/publisher",
        "license": "http://purl.org/dc/terms/license",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "volume": "http://purl.org/ontology/bibo/volume",
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}